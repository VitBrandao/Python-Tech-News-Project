# Boas-vindas ao reposit√≥rio do Tech News
---

# Requisitos obrigat√≥rios

## 1 - Crie a fun√ß√£o `fetch`
local: `tech_news/scraper.py`

Antes de fazer scrape, precisamos de uma p√°gina! Esta fun√ß√£o ser√° respons√°vel por fazer a requisi√ß√£o HTTP ao site e obter o conte√∫do HTML.
Alguns cuidados dever√£o ser tomados: como a nossa fun√ß√£o poder√° ser utilizada v√°rias vezes em sucess√£o, na nossa implementa√ß√£o devemos nos assegurar que um [Rate Limit](https://app.betrybe.com/course/computer-science/redes-e-raspagem-de-dados/raspagem-de-dados/ab38ab4e-bdbd-4984-8987-1abf32d85f26/conteudos/4edde8f1-9d55-4c98-a593-e3043848a127/alguns-problemas/) ser√° respeitado.

- A fun√ß√£o deve receber uma URL
- A fun√ß√£o deve fazer uma requisi√ß√£o HTTP `get` para esta URL utilizando a fun√ß√£o `requests.get`
- A fun√ß√£o deve retornar o conte√∫do HTML da resposta.
- A fun√ß√£o deve respeitar um Rate Limit de 1 requisi√ß√£o por segundo; Ou seja, caso chamada m√∫ltiplas vezes, ela deve aguardar 1 segundo entre cada requisi√ß√£o que fizer.
**Dica:** Uma forma simples de garantir que cada requisi√ß√£o seja feita com um intervalo m√≠nimo de um segundo √© utilizar `time.sleep(1)` antes de cada requisi√ß√£o. (Existem outras formas mais eficientes.)
- Caso a requisi√ß√£o seja bem sucedida com `Status Code 200: OK`, deve ser retornado seu conte√∫do de texto;
- Caso a resposta tenha o c√≥digo de status diferente de `200`, deve-se retornar `None`;
- Caso a requisi√ß√£o n√£o receba resposta em at√© 3 segundos, ela deve ser abandonada (este caso √© conhecido como "Timeout") e a fun√ß√£o deve retornar None.

üìå Voc√™ vai precisar definir o _header_ `user-agent` para que a raspagem do blog da Trybe funcione corretamente. Para isso, preencha com o valor `"Fake user-agent"` conforme exemplo abaixo:

```python
{ "user-agent": "Fake user-agent" }
```

<details>
  <summary>
    <b>‚úçÔ∏è Teste manual</b>
  </summary>

  Abra um terminal Python importando estas fun√ß√µes atrav√©s do comando:

  `python3 -i tech_news/scraper.py`

  Agora invoque as fun√ß√µes utilizando diferentes par√¢metros.
  Exemplo: 

  ```python
  html = fetch(url_da_noticia)
  scrape_noticia(html)
  ```
</details>

<details>
  <summary>
    <b>ü§ñ O que ser√° verificado pelo avaliador</b>
  </summary>

  - A fun√ß√£o utiliza o m√©todo get() da biblioteca requests

  - A fun√ß√£o executada com uma URL correta retorna o conte√∫do html

  - A fun√ß√£o, sofrendo timeout, retorna None

  - A fun√ß√£o retorna None quando recebe uma resposta com c√≥digo diferente de 200

  - A fun√ß√£o respeita o rate limit

</details>

## 2 - Crie a fun√ß√£o `scrape_novidades`
local: `tech_news/scraper.py`

Para conseguirmos fazer o scrape da p√°gina de uma not√≠cia, primeiro precisamos de links para v√°rias p√°ginas de not√≠cias. Estes links est√£o contidos na p√°gina inicial do blog da Trybe (https://blog.betrybe.com). 

Esta fun√ß√£o far√° o scrape da p√°gina Novidades para obter as URLs das p√°ginas de not√≠cias. Vamos utilizar as ferramentas que aprendemos no curso, como a biblioteca Parsel, para obter os dados que queremos de cada p√°gina.

- A fun√ß√£o deve receber uma string com o conte√∫do HTML da p√°gina inicial do blog
- A fun√ß√£o deve fazer o scrape do conte√∫do recebido para obter uma lista contendo as URLs das not√≠cias listadas.
    - ‚ö†Ô∏è *Aten√ß√£o:* **N√ÉO** inclua a not√≠cia em destaque da primeira p√°gina, apenas as not√≠cias dos cards.
- A fun√ß√£o deve retornar esta lista.
- Caso n√£o encontre nenhuma URL de not√≠cia, a fun√ß√£o deve retornar uma lista vazia.

<details>
  <summary>
    <b>‚úçÔ∏è Teste manual</b>
  </summary>

  Abra um terminal Python importando estas fun√ß√µes atrav√©s do comando:
  
  `python3 -i tech_news/scraper.py`
  
  Agora invoque as fun√ß√µes utilizando diferentes par√¢metros. Exemplo: 

  ```python
  html = fetch(url_da_noticia)
  scrape_novidades(html)
  ```
</details>

<details>
  <summary>
    <b>ü§ñ O que ser√° verificado pelo avaliador</b>
  </summary>

  - A fun√ß√£o retorna os dados esperados quando chamada com os par√¢metros corretos

  - A fun√ß√£o retorna uma lista vazia quando chamada com par√¢metros incorretos

</details>

## 3 - Crie a fun√ß√£o `scrape_next_page_link`
local: `tech_news/scraper.py`

Para buscar mais not√≠cias, precisaremos fazer a pagina√ß√£o, e para isto, vamos precisar do link da pr√≥xima p√°gina. Esta fun√ß√£o ser√° respons√°vel por fazer o scrape deste link.

- A fun√ß√£o deve receber como par√¢metro uma `string` contendo o conte√∫do HTML da p√°gina de novidades (https://blog.betrybe.com)
- A fun√ß√£o deve fazer o scrape deste HTML para obter a URL da pr√≥xima p√°gina.
- A fun√ß√£o deve retornar a URL obtida.
- Caso n√£o encontre o link da pr√≥xima p√°gina, a fun√ß√£o deve retornar `None`

<details>
  <summary>
    <b>ü§ñ O que ser√° verificado pelo avaliador</b>
  </summary>

  - A fun√ß√£o retorna os dados esperados quando chamada com os par√¢metros corretos

  - A fun√ß√£o retorna None quando chamada com os par√¢metros incorretos

</details>

## 4 - Crie a fun√ß√£o `scrape_noticia`
local: `tech_news/scraper.py`

Agora que sabemos pegar p√°ginas HTML, e descobrir o link de not√≠cias, √© hora de fazer o scrape dos dados que procuramos! 

- A fun√ß√£o deve receber como par√¢metro o conte√∫do HTML da p√°gina de uma √∫nica not√≠cia
- A fun√ß√£o deve, no conte√∫do recebido, buscar as informa√ß√µes das not√≠cias para preencher um dicion√°rio com os seguintes atributos:
  - `url` - link para acesso da not√≠cia.
  - `title` - t√≠tulo da not√≠cia.
  - `timestamp` - data da not√≠cia, no formato `dd/mm/AAAA`.
  - `writer` - nome da pessoa autora da not√≠cia.
  - `comments_count` - n√∫mero de coment√°rios que a not√≠cia recebeu.
    - Se a informa√ß√£o n√£o for encontrada, salve este atributo como `0` (zero)
  - `summary` - o primeiro par√°grafo da not√≠cia.
  - `tags` - lista contendo tags da not√≠cia.
  - `category` - categoria da not√≠cia.

- Exemplo de um retorno da fun√ß√£o com uma not√≠cia fict√≠cia:

```json
{
  "url": "https://blog.betrybe.com/novidades/noticia-bacana",
  "title": "Not√≠cia bacana",
  "timestamp": "04/04/2021",
  "writer": "Eu",
  "comments_count": 4,
  "summary": "Algo muito bacana aconteceu",
  "tags": ["Tecnologia", "Esportes"],
  "category": "Ferramentas",
}
  ```

üìå Muita aten√ß√£o aos tipos dos campos, por exemplo, `tags` √© uma lista, enquanto que `comments_count` √© num√©rico e `category` √© uma string.

üìå Os textos coletados em `title` e `summary` podem conter alguns caracteres vazios ao final. O teste espera que esses caracteres sejam removidos.

üìå Para o campo `comments_count`, como h√° poucas not√≠cias com coment√°rios, utilizem [esta not√≠cia](https://blog.betrybe.com/carreira/passos-fundamentais-para-aprender-a-programar/) como refer√™ncia para scrape desta informa√ß√£o.

üìå **√â bom saber que** ao fazer scraping na vida real, voc√™ est√° sempre "ref√©m" de quem construiu o site. Por exemplo, pode ser que nem toda not√≠cia tenha **exatamente** o mesmo HTML/CSS e voc√™ precise de criatividade para contornar isso. 

<details>
  <summary>
    <b>ü§ñ O que ser√° verificado pelo avaliador</b>
  </summary>

  - Ser√° verificado se a fun√ß√£o retorna o conte√∫do correto e no formato correto, dada uma p√°gina de not√≠cia exemplo.

</details>

---

#### <strong>üëç Terminou o requisito 4?</strong>
Parab√©ns! Este √© o requisito mais longo do projeto, e tamb√©m a funcionalidade central do nosso tech-news. Fa√ßa um break, tome uma √°gua, e #vamoquevamo para os pr√≥ximos requisitos!

---


## 5 - Crie a fun√ß√£o `get_tech_news` para obter as not√≠cias!
local: `tech_news/scraper.py`

Agora, chegou a hora de aplicar todas as fun√ß√µes que voc√™ acabou de fazer. Com estas ferramentas prontas, podemos fazer nosso scraper mais robusto com a pagina√ß√£o.

- A fun√ß√£o deve receber como par√¢metro um n√∫mero inteiro `n` e buscar as √∫ltimas `n` not√≠cias do site.
- Utilize as fun√ß√µes `fetch`, `scrape_novidades`, `scrape_next_page_link` e `scrape_noticia` para buscar as not√≠cias e processar seu conte√∫do.
- As not√≠cias buscadas devem ser inseridas no MongoDB; Para acessar o banco de dados, importe e utilize as fun√ß√µes que j√° temos prontas em `tech_news/database.py`
- Ap√≥s inserir as not√≠cias no banco, a fun√ß√£o deve retornar estas mesmas not√≠cias.

üìå De aqui em diante, usaremos o MongoDB.

Rodar MongoDB via Docker: `docker-compose up -d mongodb` no terminal. 
Para mais detalhes acerca do mongo com o docker, olhe o arquivo `docker-compose.yml`

Caso queira instalar e rodar o servidor MongoDB nativo na m√°quina, siga as instru√ß√µes no tutorial oficial:
Ubuntu: https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/  
MacOS:  https://docs.mongodb.com/guides/server/install/
  
Com o banco de dados rodando, o nosso m√≥dulo conseguir√° acess√°-lo sem problemas. Importe o m√≥dulo `tech_news/database.py` e chame as fun√ß√µes contidas nele.
N√£o altere as fun√ß√µes deste m√≥dulo; elas ser√£o utilizadas nos testes.

<details>
  <summary>
    <b>ü§ñ O que ser√° verificado pelo avaliador</b>
  </summary>

- A fun√ß√£o `create_news` do `tech_news/database.py` foi chamada corretamente

- A fun√ß√£o retorna a quantidade correta de not√≠cias

</details>

## 6 - Crie a fun√ß√£o `search_by_title`
local: `tech_news/analyzer/search_engine.py`

Agora que temos meios de popular nosso banco de dados com not√≠cias, podemos come√ßar a fazer as buscas! Esta fun√ß√£o ir√° fazer buscas por t√≠tulo.

- A fun√ß√£o deve receber uma string com um t√≠tulo de not√≠cia
- A fun√ß√£o deve buscar as not√≠cias do banco de dados por t√≠tulo
- A fun√ß√£o deve retornar uma lista de tuplas com as not√≠cias encontradas nesta busca. 
Exemplo: 
```python
[
  ("T√≠tulo1_aqui", "url1_aqui"),
  ("T√≠tulo2_aqui", "url2_aqui"),
  ("T√≠tulo3_aqui", "url3_aqui"),
]
```
- A busca deve ser _case insensitive_
- Caso nenhuma not√≠cia seja encontrada, deve-se retornar uma lista vazia.

üìå Lembre-se; para acesso ao banco de dados importe `db` definido no m√≥dulo `tech_news/database.py`.

<details>
  <summary>
    <b>‚úçÔ∏è Teste manual</b>
  </summary>
  Abra um terminal Python importando esta fun√ß√£o atrav√©s do comando
  
  `python3 -i tech_news/analyzer/search_engine.py`
  
  Agora invoque a fun√ß√£o utilizando diferentes par√¢metros. Exemplo:
  
  `search_by_title("Algoritmos")`.

</details>

<details>
  <summary>
    <b>ü§ñ O que ser√° verificado pelo avaliador</b>
  </summary>

  - Ser√° validado que √© poss√≠vel buscar uma not√≠cia pelo t√≠tulo com sucesso

  - Ser√° validado que ao buscar por um t√≠tulo que n√£o existe, o retorno deve ser uma lista vazia

  - Ser√° validado que √© poss√≠vel buscar uma not√≠cia com sucesso, tanto pelo t√≠tulo em mai√∫sculas como em min√∫sculas.

</details>


## 7 - Crie a fun√ß√£o `search_by_date`
local: `tech_news/analyzer/search_engine.py`

Esta fun√ß√£o ir√° buscar as not√≠cias do banco de dados por data.

- A fun√ß√£o deve receber como par√¢metro uma data no formato ISO `AAAA-mm-dd`
- A fun√ß√£o deve buscar as not√≠cias do banco de dados por data.
- A fun√ß√£o deve ter retorno no mesmo formato do requisito anterior.
- Caso a data seja inv√°lida, ou esteja em outro formato, uma exce√ß√£o `ValueError` deve ser lan√ßada com a mensagem `Data inv√°lida`.
- Caso nenhuma not√≠cia seja encontrada, deve-se retornar uma lista vazia.

üìå Lembre-se: A fun√ß√£o recebe uma data no formato ISO `AAAA-mm-dd`, mas no banco a data est√° salva no formato `dd/mm/AAAA`. **Dica:** Lembrem-se de como trabalhamos com datas nos projetos anteriores.

<details>
  <summary>
    <b>‚úçÔ∏è Teste manual</b>
  </summary>
  Abra um terminal Python importando esta fun√ß√£o atrav√©s do comando
  
  `python3 -i tech_news/analyzer/search_engine.py`
  
  Agora invoque a fun√ß√£o utilizando diferentes par√¢metros. Exemplo:
  
  `search_by_date("2021-04-04")`

</details>

<details>
  <summary>
    <b>ü§ñ O que ser√° verificado pelo avaliador</b>
  </summary>

  - Ser√° validado que √© poss√≠vel buscar uma not√≠cia pela data com sucesso

  - Ser√° validado que ao buscar por uma data que n√£o existe, o retorno deve ser uma lista vazia

  - Sera validado que ao buscar por uma data com formato inv√°lido, deve lan√ßar um erro `ValueError` com a mensagem `Data inv√°lida`.

</details>

## 8 - Crie a fun√ß√£o `search_by_tag`,
local: `tech_news/analyzer/search_engine.py`

Esta fun√ß√£o ir√° buscar as not√≠cias por tag.

- A fun√ß√£o deve receber como par√¢metro o nome da tag completo.
- A fun√ß√£o deve buscar as not√≠cias do banco de dados por tag.
- A fun√ß√£o deve ter retorno no mesmo formato do requisito anterior.
- Caso nenhuma not√≠cia seja encontrada, deve-se retornar uma lista vazia.
- A busca deve ser _case insensitive_

<details>
  <summary>
    <b>‚úçÔ∏è Teste manual</b>
  </summary>
  Abra um terminal Python importando esta fun√ß√£o atrav√©s do comando:
  
  `python3 -i tech_news/analyzer/search_engine.py`
  
  Agora invoque a fun√ß√£o utilizando diferentes par√¢metros.
  Exemplo:
  
  `search_by_tag("Tecnologia")`.

</details>


<details>
  <summary>
    <b>ü§ñ O que ser√° verificado pelo avaliador</b>
  </summary>

  - Ser√° validado que √© poss√≠vel buscar uma not√≠cia pela tag com sucesso

  - Ser√° validado que ao buscar por uma tag que n√£o existe, o retorno deve ser uma lista vazia

  - Ser√° validado que √© poss√≠vel buscar uma not√≠cia tanto pela tag em mai√∫sculas como em min√∫sculas

</details>

## 9 - Crie a fun√ß√£o `search_by_category`
local: `tech_news/analyzer/search_engine.py`

Esta fun√ß√£o ir√° buscar as not√≠cias por categoria.

- A fun√ß√£o deve receber como par√¢metro o nome da categoria completo.
- A fun√ß√£o deve buscar as not√≠cias do banco de dados por categoria.
- A fun√ß√£o deve ter retorno no mesmo formato do requisito anterior.
- Caso nenhuma not√≠cia seja encontrada, deve-se retornar uma lista vazia.
- A busca deve ser _case insensitive_

<details>
  <summary>
    <b>‚úçÔ∏è Teste manual</b>
  </summary>
  
  Abra um terminal Python importando esta fun√ß√£o atrav√©s do comando:
  
  `python3 -i tech_news/analyzer/search_engine.py`
  
  Agora invoque a fun√ß√£o utilizando diferentes par√¢metros. Exemplo:
  
  `search_by_category("Ferramentas")`.
</details>

<details>
  <summary>
    <b>ü§ñ O que ser√° verificado pelo avaliador</b>
  </summary>

  - Ser√° validado que √© poss√≠vel buscar uma not√≠cia pela categoria com sucesso

  - Ser√° validado que ao buscar por uma categoria que n√£o existe, o retorno deve ser uma lista vazia

  - Ser√° validado que √© poss√≠vel buscar uma not√≠cia tanto pela categoria em mai√∫sculas como em min√∫sculas

</details>